{"cells":[{"source":"# Exploratory Data Analysis in SQL\nUse this workspace to take notes, store sample queries, and build your own interactive cheat sheet! \n\nYou will need to connect your [SQL cells](https://workspace-docs.datacamp.com/work/sql-cell) to an integration to run a query.\n- You can use a sample integration from the dropdown menu. This includes the **Course Databases** integration, which contains tables you used in our SQL courses.\n- You can connect your own integration by following the instructions provided [here](https://workspace-docs.datacamp.com/integrations/what-is-an-integration).","metadata":{},"id":"7607bdb2-1707-4361-a984-1c443fe84370","cell_type":"markdown","attachments":{}},{"source":"## Common issues\n- Error codes\n    - Examples: 9, 99,-99\n- Missing value codes: \n    - NA, NaN, N/A, #N/A\n    - 0 = missing or 0?\n- Outlier (extreme) values\n    - Really high or low?\n    - Negative values?\n- Not really a number\n    - Examples: zip codes, survey response categorie","metadata":{},"cell_type":"markdown","id":"06f45c62-bd83-4668-965d-adedb66287e2"},{"source":"# CHAPTER 1: WHAT IS DATABASE?","metadata":{},"id":"a0ac303b-ad44-4690-a9f0-a70619fcabc4","cell_type":"markdown"},{"source":"**Start exploring a database by **\n- Identifying the tables and the **`foreign keys`** that link them.\n- Look for **`missing values`**\n- Count **`the number of observations`**\n- Join tables to understand how they're related. \n- Learn about coalescing and casting data along the way.\n\n**BASIC COMMAN FOR EDA** \n- **Couts no. of rows**: `count(*)`\n- **Count no. of columns**: `SELECT count(*) FROM information_schema.columns WHERE table_name = '---';`\n- **Count missing values**: `count(*) - count(column)`","metadata":{},"cell_type":"markdown","id":"4b2d67a7-34a2-46bf-9733-6837e9f25c5d"},{"source":"## 1.1 Explore Table Sizes ","metadata":{},"id":"540470d7-eb27-442b-b0d5-ab28b0a7da96","cell_type":"markdown"},{"source":"Let's start by exploring five related tables:\n- **stackoverflow**: questions asked on Stack Overflow with certain tags\n- **company**: information on companies related to tags in stackoverflow\n- **tag_company**: links stackoverflow to company\n- **tag_type**: type categories applied to tags in stackoverflow\n- **fortune500**: information on top US companies","metadata":{},"cell_type":"markdown","id":"1777e99d-2f7d-459b-9230-56aa9a4e8977"},{"source":"-- 1. COUNT NUMBER OF ROWS\nSELECT count(*) FROM company;\n\n-- 2. COUNT NUMBER OF COLUMNS\nSELECT count(*) FROM information_schema.columns WHERE table_name = 'company';\n\n-- 3. COUNT MISSING VALUES\n\n-- Select the count of ticker, \n-- subtract from the total number of rows, \n-- and alias as missing\nSELECT count(*) - count(ticker) AS missing\n  FROM fortune500;\n  \n-- Select the count of profits_change, \n-- subtract from total number of rows, and alias as missing\nSELECT count(*) - count(profits_change) as missing\nFROM fortune500;\n\n-- Select the count of industry, \n-- subtract from total number of rows, and alias as missing\nSELECT count(*) - count(industry) as missing\nFROM fortune500;","metadata":{"customType":"sql","dataFrameVariableName":"query1","sqlCellMode":"query","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"},"executionTime":2476,"lastSuccessfullyExecutedCode":"-- 1. COUNT NUMBER OF ROWS\nSELECT count(*) FROM company;\n\n-- 2. COUNT NUMBER OF COLUMNS\nSELECT count(*) FROM information_schema.columns WHERE table_name = 'company';\n\n-- 3. COUNT MISSING VALUES\n\n-- Select the count of ticker, \n-- subtract from the total number of rows, \n-- and alias as missing\nSELECT count(*) - count(ticker) AS missing\n  FROM fortune500;\n  \n-- Select the count of profits_change, \n-- subtract from total number of rows, and alias as missing\nSELECT count(*) - count(profits_change) as missing\nFROM fortune500;\n\n-- Select the count of industry, \n-- subtract from total number of rows, and alias as missing\nSELECT count(*) - count(industry) as missing\nFROM fortune500;","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"executionCancelledAt":null,"lastExecutedAt":1690994570821,"lastScheduledRunId":null},"cell_type":"code","id":"ca1d6179-bdc0-4956-8736-fca52ad0c41c","execution_count":null,"outputs":[{"output_type":"error","ename":"Error","evalue":"WITH datacamp_workspace__user_query AS (\n  -- 1. COUNT NUMBER OF ROWS\n  SELECT count(*) FROM company;\n  \n  -- 2. COUNT NUMBER OF COLUMNS\n  SELECT count(*) FROM information_schema.columns WHERE table_name = 'company';\n  \n  -- 3. COUNT MISSING VALUES\n  \n  -- Select the count of ticker, \n  -- subtract from the total number of rows, \n  -- and alias as missing\n  SELECT count(*) - count(ticker) AS missing\n    FROM fortune500;\n    \n  -- Select the count of profits_change, \n  -- subtract from total number of rows, and alias as missing\n  SELECT count(*) - count(profits_change) as missing\n  FROM fortune500;\n  \n  -- Select the count of industry, \n  -- subtract from total number of rows, and alias as missing\n  SELECT count(*) - count(industry) as missing\n  FROM fortune500\n)\n\nSELECT * FROM datacamp_workspace__user_query LIMIT 100 - syntax error at or near \";\"","traceback":[],"@datacamp/metadata":{"executedQuery":"WITH datacamp_workspace__user_query AS (\n  -- 1. COUNT NUMBER OF ROWS\n  SELECT count(*) FROM company;\n  \n  -- 2. COUNT NUMBER OF COLUMNS\n  SELECT count(*) FROM information_schema.columns WHERE table_name = 'company';\n  \n  -- 3. COUNT MISSING VALUES\n  \n  -- Select the count of ticker, \n  -- subtract from the total number of rows, \n  -- and alias as missing\n  SELECT count(*) - count(ticker) AS missing\n    FROM fortune500;\n    \n  -- Select the count of profits_change, \n  -- subtract from total number of rows, and alias as missing\n  SELECT count(*) - count(profits_change) as missing\n  FROM fortune500;\n  \n  -- Select the count of industry, \n  -- subtract from total number of rows, and alias as missing\n  SELECT count(*) - count(industry) as missing\n  FROM fortune500\n)\n\nSELECT * FROM datacamp_workspace__user_query LIMIT 100","executedQueryParameters":[]}}]},{"source":"### 1.2 Join Tables \n- Part of exploring a database is figuring out how tables relate to each other. The company and fortune500 tables don't have a formal relationship between them in the database, but this doesn't prevent you from joining them.\n\n- To join the tables, you need to find a column that they have in common where the values are consistent across the tables.","metadata":{},"cell_type":"markdown","id":"8b45d3eb-8783-4f53-8585-53655b6aa776"},{"source":"### 1.3 Foreign keys \nRecall that foreign keys reference another row in the database via a unique ID. Values in a foreign key column are restricted to values in the referenced column OR **NULL**.","metadata":{},"cell_type":"markdown","id":"731932c6-e7fe-46af-9bfd-71acea1d63c6"},{"source":"-- Question 1: What is the most common 'stackoverflow' 'tag_type'? What companies have a 'tag' of that type?\n\n-- Count the number of tags with each type\nSELECT type, COUNT(tag) AS count\n  FROM tag_type\n -- To get the count for each type, what do you need to do?\n GROUP BY type\n -- Order the results with the most common\n -- tag types listed first\n ORDER BY COUNT(tag) DESC;\n \n -- The most common tag type is 'Cloud' --\n \n -- Select the 3 columns desired\nSELECT company.name, tag_type.tag, tag_type.type\n  FROM company\n  \t   -- Join to the tag_company table\n       INNER JOIN tag_company \n       ON company.id = tag_company.company_id\n       -- Join to the tag_type table\n       INNER JOIN tag_type\n       ON tag_company.tag = tag_type.tag\n  -- Filter to most common type\n  WHERE type='cloud';","metadata":{"customType":"sql","dataFrameVariableName":"query","sqlCellMode":"query","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"},"executionTime":2556,"lastSuccessfullyExecutedCode":"-- Question 1: What is the most common 'stackoverflow' 'tag_type'? What companies have a 'tag' of that type?\n","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"c9a55423-d3ba-4252-95ac-e391ab8b0e18","execution_count":null,"outputs":[{"output_type":"error","ename":"Error","evalue":"WITH datacamp_workspace__user_query AS (\n  -- Question 1: What is the most common 'stackoverflow' 'tag_type'? What companies have a 'tag' of that type?\n)\n\nSELECT * FROM datacamp_workspace__user_query LIMIT 100 - syntax error at or near \")\"","traceback":[],"@datacamp/metadata":{"executedQuery":"WITH datacamp_workspace__user_query AS (\n  -- Question 1: What is the most common 'stackoverflow' 'tag_type'\\? What companies have a 'tag' of that type\\?\n)\n\nSELECT * FROM datacamp_workspace__user_query LIMIT 100","executedQueryParameters":[]}}]},{"source":"### 1.4 'Coalesce' Function and Coalescde with self-join\nThe `coalesce()` function can be useful for specifying a default or backup value when a column contains NULL values.\n`coalesce()` checks arguments in order and returns the first non-NULL value, if one exists.\n\n- `coalesce(NULL, 1, 2) = 1`\n- `coalesce(NULL, NULL) = NULL`\n- `coalesce(2, 3, NULL) = 2`\nIn the `fortune500` data, `industry` contains some missing values. Use `coalesce()` to use the value of `sector` as the industry when `industry` is `NULL`. Then find the most common industry.","metadata":{},"cell_type":"markdown","id":"a8796816-6d4d-4f2b-bf7a-d359135b1698"},{"source":"-- In the fortune500 data, industry contains some missing values. Use coalesce() to use the value of sector as the industry when industry is NULL. Then find the most common industry.\n\n-- Use coalesce\nSELECT coalesce(industry, sector, 'Unknown') AS industry2,\n       -- Don't forget to count!\n       COUNT(*)\n  FROM fortune500 \n-- Group by what? (What are you counting by?)\n GROUP BY industry2\n-- Order results to see most common first\n ORDER BY COUNT(*) DESC\n-- Limit results to get just the one value you want\n LIMIT 1;","metadata":{"customType":"sql","dataFrameVariableName":"df1","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"0f90c1f9-a4fe-4b64-8161-0efc8fb6c364","execution_count":null,"outputs":[]},{"source":"### 1.5 Effects of casting","metadata":{},"cell_type":"markdown","id":"c1f89216-990a-4df8-b2a1-e1bd03d1d409"},{"source":"When you cast data from one type to another, information can be lost or changed. See how the casting changes values and practice casting data using the CAST() function and the :: syntax.\n\n`SELECT CAST(value AS new_type);` == `SELECT value::new_type;`","metadata":{},"cell_type":"markdown","id":"44dce8b4-27e6-4003-a29a-b66e1b7b9582"},{"source":"# CHAPTER 2: NUMERIC DATA TYPES & SUMMARY FUCTIONS","metadata":{},"cell_type":"markdown","id":"4fccab7a-bee9-42da-928d-dae4fe772aa9"},{"source":"More exploration with: \n- **Summary functions**: `max`, `min`, `avg`, `stddev_samp()`, `stddev_pop()`,`var_pop()`, `var_samp()`\n- **Explore with division**: for example, `unanswered_count/question_count::numeric`\n- **Explor with distribution:** \n    - `trunc()` truncates numbers by replacing lower place value digits with zeros\n    - `generate_series(from, to, step)` \n- **More summary functions:**\n    - `corr(col1,col2 )`: correlation between two columns\n    - `percentile_disc(percentile) WITHIN GROUP (ORDER BY column_name)`: median at 50 percentile","metadata":{},"cell_type":"markdown","id":"bec3975d-f699-4371-9dcc-b4a666a9806f"},{"source":"### 1.1 EXPLORE WITH DIVISION & DISTRIBUTION\n- **Explore with division**: for example, `unanswered_count/question_count::numeric`\n- **Explor with distribution:** \n    - `trunc()` truncates numbers by replacing lower place value digits with zeros\n    - `generate_series(from, to, step)` ","metadata":{},"cell_type":"markdown","id":"fb1a4719-f76c-4842-b12e-e4814e888b09"},{"source":"-- QUESTION: What information does the 'unanswered_pct' column in the stackoverflow table contain?\n\n-- Divide unanswered_count by question_count\nSELECT unanswered_count/question_count::numeric AS computed_pct, \n       -- What are you comparing the above quantity to?\n       unanswered_pct\n  FROM stackoverflow\n -- Select rows where question_count is not 0\n WHERE question_count != 0 \n LIMIT 10;\n \n -- ANSWER:  \"unanswered_pct\" is the percent of unanswered questions on Stack Overflow with the tag, not the percent of questions with the tag that are unanswered.","metadata":{"customType":"sql","dataFrameVariableName":"df","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"},"executionCancelledAt":null,"executionTime":3270,"lastExecutedAt":1690997605523,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"-- What information does the 'unanswered_pct' column in the stackoverflow table contain?\n-- Divide unanswered_count by question_count\nSELECT unanswered_count/question_count::numeric AS computed_pct, \n       -- What are you comparing the above quantity to?\n       unanswered_pct\n  FROM stackoverflow\n -- Select rows where question_count is not 0\n WHERE question_count != 0 \n LIMIT 10;\n \n -- ANSWER:  \"unanswered_pct\" is the percent of unanswered questions on Stack Overflow with the tag, not the percent of questions with the tag that are unanswered.","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"6c88668e-9091-426e-9fe2-3eb05e0f8758","execution_count":null,"outputs":[{"output_type":"error","ename":"Error","evalue":"-- What information does the 'unanswered_pct' column in the stackoverflow table contain?\n-- Divide unanswered_count by question_count\nSELECT unanswered_count/question_count::numeric AS computed_pct, \n       -- What are you comparing the above quantity to?\n       unanswered_pct\n  FROM stackoverflow\n -- Select rows where question_count is not 0\n WHERE question_count != 0 \n LIMIT 10;\n \n -- ANSWER:  \"unanswered_pct\" is the percent of unanswered questions on Stack Overflow with the tag, not the percent of questions with the tag that are unanswered. - relation \"stackoverflow\" does not exist","traceback":[],"@datacamp/metadata":{"executedQuery":"-- What information does the 'unanswered_pct' column in the stackoverflow table contain\\?\n-- Divide unanswered_count by question_count\nSELECT unanswered_count/question_count::numeric AS computed_pct, \n       -- What are you comparing the above quantity to\\?\n       unanswered_pct\n  FROM stackoverflow\n -- Select rows where question_count is not 0\n WHERE question_count != 0 \n LIMIT 10;\n \n -- ANSWER:  \"unanswered_pct\" is the percent of unanswered questions on Stack Overflow with the tag, not the percent of questions with the tag that are unanswered.","executedQueryParameters":[]}}]},{"source":"-- QUESTION: Summarize the distribution of the number of questions with the tag \"dropbox\" on Stack Overflow per day by binning the data.\n\n-- Bins created in Step 2\nWITH bins AS (\n      SELECT generate_series(2200, 3050, 50) AS lower,\n             generate_series(2250, 3100, 50) AS upper),\n     -- Subset stackoverflow to just tag dropbox (Step 1)\n     dropbox AS (\n      SELECT question_count \n        FROM stackoverflow\n       WHERE tag='dropbox') \n-- Select columns for result\n-- What column are you counting to summarize?\nSELECT lower, upper, count(question_count) \n  FROM bins  -- Created above\n       -- Join to dropbox (created above), \n       -- keeping all rows from the bins table in the join\n       LEFT JOIN dropbox\n       -- Compare question_count to lower and upper\n         ON question_count >= lower \n        AND question_count < upper\n -- Group by lower and upper to count values in each bin\n GROUP BY lower, upper\n -- Order by lower to put bins in order\n ORDER BY lower;\n \n -- Outcome: 18 rows affected ","metadata":{"customType":"sql","dataFrameVariableName":"df2","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"1069fb95-36ba-4b0f-8adc-ccd907ea79f9","execution_count":null,"outputs":[]},{"source":"### 1.2 MORE SUMMARY FUNCTIONS\n- `corr(col1,col2 )` correlation between two columns\n- `percentile_disc(percentile) WITHIN GROUP (ORDER BY column_name)`: median at 50 percentile","metadata":{},"cell_type":"markdown","id":"c68f27f6-3f28-4d08-9757-92d2b6b71ffa"},{"source":"-- Compute the mean (avg()) and median assets of Fortune 500 companies by sector.\n\n-- What groups are you computing statistics by?\nSELECT sector,\n       -- Select the mean of assets with the avg function\n       avg(assets) AS mean,\n       -- Select the median\n       percentile_disc(0.5) WITHIN GROUP (ORDER BY assets) AS median\n  FROM fortune500\n -- Computing statistics for each what?\n GROUP BY sector\n -- Order results by a value of interest\n ORDER BY mean;","metadata":{"customType":"sql","dataFrameVariableName":"df3","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"f06c8e4b-1b63-40f5-a9f9-874996b27bbe","execution_count":null,"outputs":[]},{"source":"### 1.3 TEMP TABLE \n- **Create TEMP TABLE Syntax** \n##### -- Create table as \n`CREATE TEMP TABLE new_tablename AS`\n##### -- Query results to store in the table\n`SELECT column1, column2`\n`FROM table;`\n\n- **Select Into Syntax** \n#### -- Select existing columns\n`SELECT column1, column2`\n##### -- Clause to direct results to a new temp table\n`INTO TEMP TABLE new_tablename`\n-- Existing table with exisitng columns\n`FROM table;`","metadata":{},"cell_type":"markdown","id":"e44947d0-e6b3-45d7-9772-dcb7db717c83"},{"source":"-- QUESTION: How many questions had each tag on the first date for which data for the tag is available?\n-- QUESTION: How many questions had the tag on the last day?\n-- QUESTION: Also, compute the difference between these two values.\n-- To clear table if it already exists\nDROP TABLE IF EXISTS startdates;\n\nCREATE TEMP TABLE startdates AS\nSELECT tag, min(date) AS mindate\n  FROM stackoverflow\n GROUP BY tag;\n \n-- Select tag (Remember the table name!) and mindate\nSELECT startdates.mindate, \n       -- Select question count on the min and max days\n\t   so_min.question_count AS min_date_question_count,\n       so_max.question_count AS max_date_question_count,\n       -- Compute the change in question_count (max- min)\n       so_max.question_count - so_min.question_count AS change\n  FROM startdates\n       -- Join startdates to stackoverflow with alias so_min\n       INNER JOIN stackoverflow AS so_min\n          -- What needs to match between tables?\n          ON startdates.tag = so_min.tag\n         AND startdates.mindate = so_min.date\n       -- Join to stackoverflow again with alias so_max\n       INNER JOIN stackoverflow AS so_max\n       \t  -- Again, what needs to match between tables?\n          ON startdates.tag = so_max.tag\n         AND so_max.date = '2018-09-25';\n","metadata":{"customType":"sql","dataFrameVariableName":"df4","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"83392c45-0d47-4814-9dce-b123781f821c","execution_count":null,"outputs":[]},{"source":"### 1.4 INSERT INTO TEMP TABLE\n- `INSERT INTO` top_companies\n- `SELECT` rank, title\n- `FROM` fortune500\n- `WHERE` rank `BETWEEN` 11 AND 20;","metadata":{},"cell_type":"markdown","id":"637d4d4d-5885-4ab6-ba3e-709f64dd4e02"},{"source":"# CHAPTER 3: Character data types and common issues\n\n- **DATABASE: evanston311**\n    - `street`column:  Street name\n    - `description` column:  the details of the inquiry\n    - `category` column:  the column groups inquiries into different types.","metadata":{},"cell_type":"markdown","id":"5d9496e5-1534-4d33-a657-d23dfd770e32"},{"source":"## 3.1  Character data types and common issues","metadata":{},"cell_type":"markdown","id":"43d55d4a-0796-44d6-844d-0774120a3d68"},{"source":"- **Database: evanston311**\n- Using `count(*)` and `GROUP BY` to count categories\n- Using `LIKE` to find out extra space in the beginning or end of values ","metadata":{},"cell_type":"markdown","id":"28fa8e96-bfd6-407e-90f5-575a6a886b6d"},{"source":"## 3.2 ISSUE 2: Cases and Spaces","metadata":{},"cell_type":"markdown","id":"66db948e-e17d-4c89-a6af-1b2a15ad436d"},{"source":"1. **Case sensitivity`'apple' != 'Apple'`**\n    - `lower()` OR `upper()` for converting case\n3. **Spaces count: `' apple' != 'apple'` OR `'' != ' '`**\n    - Using `LIKE '%apple%'` OR `IKIKE` for case insensitive\n    - `trim(column_name, char to be trimmed)`\n5. **Empty strings aren't null: `'' != NULL`**\n6. **Punctuation differences: `'to-do' != 'toâ€“do'`**\n","metadata":{},"cell_type":"markdown","id":"7db28fb3-cf30-48bf-90f4-00ecf38164d4"},{"source":"-- Any issues in the 'Street' name? \n-- Remove the house numbers, extra punctuation, and any spaces from the beginning and end of the street values as a first attempt at cleaning up the values.\nSELECT distinct street,\n       -- Trim off unwanted characters from street\n       trim(street, '0123456789 #/.') AS cleaned_street\n  FROM evanston311\n ORDER BY street;","metadata":{"customType":"sql","dataFrameVariableName":"df5","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"34fa766b-2962-46cb-9ee6-875be6e878a2","execution_count":null,"outputs":[]},{"source":"-- Find the most common categories for rows with a description about trash that don't have a trash-related category.\n-- Count rows with each category\nSELECT category, count(*)\n  FROM evanston311 \n WHERE (description ILIKE '%trash%'\n    OR description ILIKE '%garbage%') \n   AND category NOT LIKE '%Trash%'\n   AND category NOT LIKE '%Garbage%'\n -- What are you counting?\n GROUP BY category\n --- order by most frequent values\n ORDER BY count(*) DESC\n LIMIT 10;","metadata":{"customType":"sql","dataFrameVariableName":"df6","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"de0f9ad2-1cc0-44e9-ae2d-0fcd8fa282fb","execution_count":null,"outputs":[]},{"source":"## 3.3 ISSUE 3 - Bring order to messy text","metadata":{},"cell_type":"markdown","id":"5663a466-cc14-4be9-9ce2-baeb5045e909"},{"source":"### Splitting and concatenating text\n- **Choose the first n characters: `left(column_name, n)`**\n- **Choose the last n characters: `right(column_name, n)`**\n- **Choose substring from specific position: `substring(string FROM start FOR length);`**\n- **Splitting on a delimiter: `SELECT split_part(string, delimiter, part)`;**\n- **Concatenating text: using `concat()` OR `||` OR `concat_ws(separator, string 1, string 2, ...)` ** \n    - `SELECT concat('a', NULL,'cc');` -- result: **acc**\n    - `SELECT concat('a', 2,'cc');` -- result: a2cc\n    - `SELECT 'a' || 2 || 'cc'`;  - result: a2cc\n    - `SELECT 'a' || NULL || 'cc';` -- result: (empty)\n","metadata":{},"cell_type":"markdown","id":"a59a7ea1-4c35-455d-af3f-0a29072f33c2"},{"source":"-- QUESTION: Extract just the first word of each street value to find the most common streets regardless of the suffix.\n-- Select the first word of the street value\nSELECT split_part(street,' ', 1) AS street_name, \n       count(*)\n  FROM evanston311\n GROUP BY street_name\n ORDER BY count DESC\n LIMIT 20;","metadata":{"customType":"sql","dataFrameVariableName":"df7","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"12d5fac5-d5ad-40e9-8958-3ac6b63c80e4","execution_count":null,"outputs":[]},{"source":"-- QUESTION: Select the first 50 characters of description when description starts with the word \"I\".\n\n-- Select the first 50 chars when length is greater than 50\nSELECT CASE WHEN length(description) > 50\n            THEN left(description, 50) || '...'\n       -- otherwise just select description\n       ELSE description\n       END\n  FROM evanston311\n -- limit to descriptions that start with the word I\n WHERE description LIKE 'I %'\n ORDER BY description;","metadata":{"customType":"sql","dataFrameVariableName":"df8","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"824fd5e2-b6d8-46bc-ac65-e0d69a7c6925","execution_count":null,"outputs":[]},{"source":"### 3.4 ISSUE 4: MULTIPLE TRANSFORMATIONS\n- **Step 1: `CREATE TEMP TABLE`**\n- **Step 2: `UPDATE` values **\n    - `UPDATE`** table_name**\n        `SET` **column_name = new_value**\n         `WHERE` **condition** \n- **Step 3: `JOIN` original and `TEMP` table**","metadata":{},"cell_type":"markdown","id":"a636dc04-8ea9-494c-9f47-966db0359945"},{"source":"-- QUESTION: Choose the main category 'Trach Cart', 'Snow removal' and count of each \n\n-- Step 1: CREATE TEMP TABLE\nDROP TABLE IF EXISTS recode;\nCREATE TEMP TABLE recode AS\n  SELECT DISTINCT category, \n         rtrim(split_part(category, '-', 1)) AS standardized\n  FROM evanston311;\n-- Step 2: UPDATE THE TEMP TABLE\nUPDATE recode SET standardized='Trash Cart' \n WHERE standardized LIKE 'Trash%Cart';\nUPDATE recode SET standardized='Snow Removal' \n WHERE standardized LIKE 'Snow%Removal%';\nUPDATE recode SET standardized='UNUSED' \n WHERE standardized IN ('THIS REQUEST IS INACTIVE...Trash Cart', \n               '(DO NOT USE) Water Bill',\n               'DO NOT USE Trash', 'NO LONGER IN USE');\n\n-- Step 3: JOIN BOTH TABLES \n-- Select the recoded categories and the count of each\nSELECT standardized, count(*)\n-- From the original table and table with recoded values\n  FROM evanston311 \n       INNER JOIN recode \n       -- What column do they have in common?\n       ON evanston311.category = recode.category \n -- What do you need to group by to count?\n GROUP BY standardized\n -- Display the most common val values first\n ORDER BY count(*) DESC;","metadata":{"customType":"sql","dataFrameVariableName":"df9","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"296cfd90-d02b-40ed-92d4-cdc62ac3a6dd","execution_count":null,"outputs":[]},{"source":"Tips and Tricks: **Create TEMP TABLE wirh indivator variables**\n- **Using `cast(col_name LIKE string as integer)` - `LIKE` produces `True` or `False` as a result, but casting a boolean (True or False) as an `integer`**","metadata":{},"cell_type":"markdown","id":"04e13ab1-ee90-44ef-97fe-42d3f2f9745d"},{"source":"-- To clear table if it already exists\nDROP TABLE IF EXISTS indicators;\n\n-- Create the indicators temp table\nCREATE TEMP TABLE indicators AS\n  -- Select id\n  SELECT id, \n         -- Create the email indicator (find @) \n         CAST (description LIKE '%@%' AS integer) AS email,\n         -- Create the phone indicator\n         CAST(description LIKE '%___-___-____%' AS integer) AS phone \n    -- What table contains the data? \n    FROM evanston311;\n\n-- Select the column you'll group by\nSELECT priority,\n       -- Compute the proportion of rows with each indicator\n       sum(email)/count(*)::numeric AS email_prop, \n       sum(phone)/count(*)::numeric AS phone_prop\n  -- Tables to select from\n  FROM evanston311\n       LEFT JOIN indicators\n       -- Joining condition\n       ON evanston311.id=indicators.id\n -- What are you grouping by?\n GROUP BY priority;","metadata":{"customType":"sql","dataFrameVariableName":"df10","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"26cd3d43-642c-46b0-8524-005548bd1d45","execution_count":null,"outputs":[]},{"source":"# CHAPTER 4: DATE/TIME TYPE AND FORMATS","metadata":{},"cell_type":"markdown","id":"52734b9b-1753-43bc-bc84-e3dfeaba90d9"},{"source":"## 4.1 Main Date & Time Types \n- **date**: `YYYY-MM-DD`. Example: `2018-12-30`\n- **timestamp**: `YYYY-MM-DD HH:MM:SS`, for example: `2018-12-30 13.03`\n- **interval**: `6 days 01:48:08`, `00:51:03`,`1 day 21:57:47`\n- **Timestamp with timezone**: `YYYY-MM-DD HH:MM:SS+HH`. Example: `2004-10-19 10:23:54+02`","metadata":{},"cell_type":"markdown","id":"0b775f6b-3e2f-4cae-8e45-da34361485f6"},{"source":"## 4.2 Date and time comparisons \n- Compare with `>` , `<` , `=`. Example: `SELECT '2018-01-01' > '2017-12-31';`\n- `now()` : current timestamp. Example: `SELECT now() > '2017-12-31';`\n\n#### 4.2.1 Date Addition\n- `SELECT '2018-12-10'::date + '1 year 2 days 3 minutes'::interval ;`\n    - Result: `2019-12-12 00:03:00`\n#### 4.2.2 Date Subtraction \n- `SELECT now() - '2015-01-01';`\n    - Result: `1439 days 21:32:22.616076`","metadata":{},"cell_type":"markdown","id":"d563762c-88a6-4666-aa31-7809c08a58a2"},{"source":"-- Add 100 days to the current timestamp\nSELECT now(), now() +'100 days'::interval;\n\n-- Select the current timestamp, \n-- and the current timestamp + 5 minutes\nSELECT now(), now() + '5 minutes'::interval;\n\n-- Select the category and the average completion time by category\nSELECT category, \n       AVG(date_completed - date_created) AS completion_time\n  FROM evanston311\n GROUP BY category\n-- Order the results\n ORDER BY completion_time DESC;","metadata":{"customType":"sql","dataFrameVariableName":"df11","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"bc69d7c8-16c2-4cef-b662-c52c6f8ab13a","execution_count":null,"outputs":[]},{"source":"## 4.3 Date/time components and aggregation","metadata":{},"cell_type":"markdown","id":"a7d8650f-8e6d-4fc2-bae0-1253dedd2d11"},{"source":"### 4.3.1 Common date/time fields","metadata":{},"cell_type":"markdown","id":"6910eeed-5fd2-4311-bbf0-26d968a4a3ac"},{"source":"- `century`: 2019-01-01 = `century 21 `\n- decade: 2019-01-01 = `decade 201` \n- `year`, `month`, `day` \n- `hour`, `minute`, `second`\n- `week` \n- `dow`: day of week","metadata":{},"cell_type":"markdown","id":"741b543a-c558-45d3-878d-1b246016abf1"},{"source":"### 4.3.2 Date/time Components and Aggregation","metadata":{},"cell_type":"markdown","id":"07b10517-aa27-4e68-958a-8f2d39c56fe8"},{"source":"- **Extracting Function:** `date_part('field', timestamp)` OR `EXTRACT(FIELD FROM timestamp)`\n- **Getting the name of the day of the week**: `to_char(date_created, 'day')`\n- **Truncating dates:** `date_trunc('field', timestamp)`\n    - Example: **SELECT date_trunc('month', now());**. Result: `2018-12-01 00:00:00`","metadata":{},"cell_type":"markdown","id":"be5ce449-00db-469a-a9a3-150bf8fa643c"},{"source":"-- Variation by day of week\n\n-- Select name of the day of the week the request was created \nSELECT to_char(date_created, 'day') AS day, \n       -- Select avg time between request creation and completion\n       AVG(date_completed - date_created) AS duration\n  FROM evanston311 \n -- Group by the name of the day of the week and \n -- integer value of day of week the request was created\n GROUP BY day, EXTRACT(DOW FROM date_created)\n -- Order by integer value of the day of the week \n -- the request was created\n ORDER BY EXTRACT(DOW FROM date_created);","metadata":{"customType":"sql","dataFrameVariableName":"df12","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"},"executionCancelledAt":null,"executionTime":2294,"lastExecutedAt":1691340994434,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"// Variation by day of week\n\n-- Select name of the day of the week the request was created \nSELECT to_char(date_created, 'day') AS day, \n       -- Select avg time between request creation and completion\n       AVG(date_completed - date_created) AS duration\n  FROM evanston311 \n -- Group by the name of the day of the week and \n -- integer value of day of week the request was created\n GROUP BY day, EXTRACT(DOW FROM date_created)\n -- Order by integer value of the day of the week \n -- the request was created\n ORDER BY EXTRACT(DOW FROM date_created);","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"196645a5-3e32-482a-bf66-5d71376d61e4","execution_count":null,"outputs":[{"output_type":"error","ename":"Error","evalue":"// Variation by day of week\n\n-- Select name of the day of the week the request was created \nSELECT to_char(date_created, 'day') AS day, \n       -- Select avg time between request creation and completion\n       AVG(date_completed - date_created) AS duration\n  FROM evanston311 \n -- Group by the name of the day of the week and \n -- integer value of day of week the request was created\n GROUP BY day, EXTRACT(DOW FROM date_created)\n -- Order by integer value of the day of the week \n -- the request was created\n ORDER BY EXTRACT(DOW FROM date_created); - syntax error at or near \"//\"","traceback":[],"@datacamp/metadata":{"executedQuery":"// Variation by day of week\n\n-- Select name of the day of the week the request was created \nSELECT to_char(date_created, 'day') AS day, \n       -- Select avg time between request creation and completion\n       AVG(date_completed - date_created) AS duration\n  FROM evanston311 \n -- Group by the name of the day of the week and \n -- integer value of day of week the request was created\n GROUP BY day, EXTRACT(DOW FROM date_created)\n -- Order by integer value of the day of the week \n -- the request was created\n ORDER BY EXTRACT(DOW FROM date_created);","executedQueryParameters":[]}}]},{"source":"-- Aggregate daily counts by month\nSELECT date_trunc('month', day) AS month,\n       avg(count)\n  -- Subquery to compute daily counts\n  FROM (SELECT date_trunc('day',date_created) AS day,\n               count(*) AS count\n          FROM evanston311\n         GROUP BY day) AS daily_count\n GROUP BY month\n ORDER BY month;","metadata":{"customType":"sql","dataFrameVariableName":"df13","sqlCellMode":"dataFrame","sqlSource":{"integrationId":"c632441c-e1dc-4637-a56d-10b85efd89be","type":"integration"}},"cell_type":"code","id":"0a1fd300-f3ac-478b-941f-3da155eda388","execution_count":null,"outputs":[]},{"source":"## 4.4 Aggregating withdate/time series","metadata":{},"cell_type":"markdown","id":"f172327e-e725-4c70-83fc-885ddccf664c"},{"source":"### 4.4.1 Generate series\n- **Syntax:** `SELECT generate_series(from, to, interval);`\n- **Generate series from he beginning**\n    - `SELECT generate_series('2018-01-31','2018-12-31','1 month'::interval);` \n    - -- Subtract 1 day to get end of month\nSELECT generate_series('2018-02-01',\n-- start 1 month late\n'2019-01-01'\n,\n'1 month'::interval) -\n'1 day'::interval","metadata":{},"cell_type":"markdown","id":"978e02a3-02d6-4f3e-9821-b2885f62c1e4"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}